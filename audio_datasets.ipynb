{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from librosa import logamplitude\n",
    "from librosa.feature import melspectrogram\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import *\n",
    "\n",
    "root_dir = ''\n",
    "train_audio = 'train/audio'\n",
    "test_audio = 'test/audio'\n",
    "df = {}\n",
    "calc_mels = True\n",
    "\n",
    "# create list of classes\n",
    "classes = os.listdir(os.path.join(root_dir, train_audio))\n",
    "classes.remove('_background_noise_')\n",
    "#         self.classes.append('silence')\n",
    "\n",
    "# create dataframe of training meta data\n",
    "tr_f_l = []\n",
    "for c in classes:\n",
    "    files_cl = os.listdir(os.path.join(root_dir, train_audio, c))\n",
    "    for f in files_cl:\n",
    "        speaker, _, utter_no = f[:-4].split('_')\n",
    "        path_file = os.path.join(root_dir, train_audio, c, f)\n",
    "        tr_f_l.append((speaker, int(utter_no), 1, c, path_file))\n",
    "columns = 'speaker utter_no label class_name file'.split()\n",
    "df['train_all'] = pd.DataFrame(tr_f_l, columns=columns)\n",
    "cl_map = lambda x: classes.index(x['class_name'])\n",
    "df['train_all'].label = df['train_all'].apply(cl_map, axis=1)\n",
    "df['train_all']['idx'] = df['train_all'].index\n",
    "\n",
    "# split training data into training and validation, done on a speaker basis to\n",
    "# avoid having samples from the same speaker in different sets\n",
    "val_pct=0.20\n",
    "\n",
    "speakers = df['train_all'].speaker.unique()\n",
    "\n",
    "if calc_mels:\n",
    "    idx = np.load('idx.npy')\n",
    "else:\n",
    "    idx = np.random.randint(len(speakers), size = int((len(speakers) * val_pct)))\n",
    "    np.save('idx.npy', idx)\n",
    "\n",
    "val = speakers[idx]\n",
    "df['val'] = df['train_all'][df['train_all'].speaker.isin(val)]\n",
    "df['train'] = df['train_all'][~df['train_all'].speaker.isin(val)]\n",
    "\n",
    "# create dataframe of test file names\n",
    "test_files  = os.listdir(os.path.join(root_dir, test_audio))\n",
    "test_files = list(map(lambda x: os.path.join(test_audio, x), test_files))\n",
    "                         \n",
    "# test_files = map(lambda x: os.path.join(test_audio, x), test_files)\n",
    "df['test'] = pd.DataFrame(test_files)\n",
    "df['test'].columns = ['file']\n",
    "df['test']['label'] = -1\n",
    "\n",
    "# specify mel spectrogram function\n",
    "n_fft=500\n",
    "hop_length=161\n",
    "n_mels=100\n",
    "fmax=8000\n",
    "\n",
    "def mel_spec(samples, rate):\n",
    "    S = melspectrogram(samples, rate, power=1, n_fft=n_fft,\n",
    "                       hop_length=hop_length, n_mels=n_mels, fmax=8000)\n",
    "    log_S = logamplitude(S, ref_power=np.max)\n",
    "    return log_S, rate\n",
    "\n",
    "# create mel spectrograms for each set, adding zeros at the end of any\n",
    "# wav file less than 16k samples\n",
    "\n",
    "def get_mel(f, i):\n",
    "    samp_arr = np.zeros(16000, dtype=np.float32)\n",
    "    rate, samples = wavfile.read(f)\n",
    "    samp_arr[:len(samples)] = samples\n",
    "    m_samp, _ = mel_spec(samp_arr, rate)\n",
    "    mels[i] = m_samp\n",
    "\n",
    "ms = {}\n",
    "if not calc_mels:\n",
    "    for split in ['train_all', 'test']:\n",
    "        ms[split] = np.load('{}.npy'.format(split))\n",
    "\n",
    "class AudioData(Dataset):\n",
    "    def __init__(self, split, transform=None):\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.labels = df[split].label\n",
    "        self.idxs = df[split].index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(df[split])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if split == 'test':\n",
    "            data = ms['test'][idx]\n",
    "        else:\n",
    "            data = ms['train_all'][self.idxs[idx]]\n",
    "            \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, label, idx\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     if calc_mels:\n",
    "        for split in ['train_all', 'test']:\n",
    "            with Pool(processes=2) as p:\n",
    "                max_ = len(df[split])\n",
    "                with tqdm(total=max_) as pbar:\n",
    "                    for i, _ in tqdm(\n",
    "                        (p.starmap(get_mel,zip(df[split].file, df[split].index)))):\n",
    "                        pbar.update()\n",
    "                ms[split] = mels\n",
    "                np.save('{}.npy', mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['train'].file, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52769, 100, 100)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mels = np.concatenate([ms['train'], ms['val']], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.665177041704762"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mels.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-29.836362884868944"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mels.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mels.std((0, 1)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
